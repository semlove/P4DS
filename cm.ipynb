{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data set loading\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Data preparation\n",
    "X=pd.DataFrame(digits.data)\n",
    "y=pd.Series(digits.target, name='Actual')\n",
    "\n",
    "# preperation of train, test data set\n",
    "X_tr, X_t, y_tr, y_t = model_selection.train_test_split(X, y, test_size=0.30,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gskim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\gskim\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.89      0.90      0.90        52\n",
      "           2       0.96      0.96      0.96        53\n",
      "           3       0.93      0.96      0.95        54\n",
      "           4       0.98      1.00      0.99        48\n",
      "           5       0.98      0.96      0.97        57\n",
      "           6       0.95      0.98      0.97        60\n",
      "           7       1.00      0.94      0.97        53\n",
      "           8       0.92      0.90      0.91        61\n",
      "           9       0.95      0.93      0.94        57\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9537037037037037\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  2  0  3  0]\n",
      " [ 0  0 51  2  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 55  1  0  0  0]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  1  0  1  1  0  0 50  0  0]\n",
      " [ 0  3  1  0  0  0  0  0 55  2]\n",
      " [ 0  0  0  1  0  1  0  0  2 53]]\n"
     ]
    }
   ],
   "source": [
    "# Model selection using Logistic Regression analysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        52\n",
      "           2       1.00      0.98      0.99        53\n",
      "           3       1.00      1.00      1.00        54\n",
      "           4       1.00      1.00      1.00        48\n",
      "           5       0.98      0.96      0.97        57\n",
      "           6       0.98      1.00      0.99        60\n",
      "           7       0.98      1.00      0.99        53\n",
      "           8       1.00      1.00      1.00        61\n",
      "           9       0.98      0.98      0.98        57\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9925925925925926\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 52  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 54  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 48  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 55  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 53  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 56]]\n"
     ]
    }
   ],
   "source": [
    "# Model selection using Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma=0.001)\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.74      0.88      0.81        52\n",
      "           2       0.96      0.49      0.65        53\n",
      "           3       0.66      0.85      0.74        54\n",
      "           4       0.95      0.75      0.84        48\n",
      "           5       0.98      0.89      0.94        57\n",
      "           6       0.95      0.98      0.97        60\n",
      "           7       0.79      0.98      0.87        53\n",
      "           8       0.61      0.84      0.70        61\n",
      "           9       0.97      0.58      0.73        57\n",
      "\n",
      "    accuracy                           0.82       540\n",
      "   macro avg       0.86      0.83      0.82       540\n",
      "weighted avg       0.86      0.82      0.82       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.8240740740740741\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 46  0  0  0  0  0  0  6  0]\n",
      " [ 0  6 26  5  0  0  0  0 16  0]\n",
      " [ 0  0  0 46  0  0  0  1  6  1]\n",
      " [ 0  3  0  0 36  0  2  7  0  0]\n",
      " [ 0  1  0  2  0 51  1  2  0  0]\n",
      " [ 0  0  1  0  0  0 59  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 52  0  0]\n",
      " [ 0  5  0  3  0  1  0  1 51  0]\n",
      " [ 0  1  0 14  1  0  0  3  5 33]]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform') Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.98      0.98      0.98        52\n",
      "           2       0.98      0.98      0.98        53\n",
      "           3       0.98      0.98      0.98        54\n",
      "           4       1.00      0.98      0.99        48\n",
      "           5       0.96      0.96      0.96        57\n",
      "           6       0.97      1.00      0.98        60\n",
      "           7       0.96      1.00      0.98        53\n",
      "           8       1.00      0.95      0.97        61\n",
      "           9       0.98      0.98      0.98        57\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9814814814814815\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  0  0  1  0  0]\n",
      " [ 0  0  1 53  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 47  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 55  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 60  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 53  0  0]\n",
      " [ 0  1  0  1  0  0  1  0 58  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 56]]\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89        45\n",
      "           1       0.81      0.83      0.82        52\n",
      "           2       0.89      0.77      0.83        53\n",
      "           3       0.73      0.85      0.79        54\n",
      "           4       0.86      0.90      0.88        48\n",
      "           5       0.86      0.88      0.87        57\n",
      "           6       0.92      0.90      0.91        60\n",
      "           7       0.85      0.83      0.84        53\n",
      "           8       0.86      0.72      0.79        61\n",
      "           9       0.77      0.82      0.80        57\n",
      "\n",
      "    accuracy                           0.84       540\n",
      "   macro avg       0.84      0.84      0.84       540\n",
      "weighted avg       0.84      0.84      0.84       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.8388888888888889\n",
      "Confusion matrix:\n",
      "[[41  0  0  0  1  1  0  0  0  2]\n",
      " [ 0 43  0  1  4  1  2  0  0  1]\n",
      " [ 1  0 41  5  0  1  3  0  1  1]\n",
      " [ 0  0  2 46  0  0  0  2  3  1]\n",
      " [ 1  1  0  0 43  1  0  1  1  0]\n",
      " [ 1  0  0  1  0 50  0  2  0  3]\n",
      " [ 1  2  1  0  2  0 54  0  0  0]\n",
      " [ 1  2  0  4  0  0  0 44  1  1]\n",
      " [ 1  4  2  4  0  0  0  1 44  5]\n",
      " [ 0  1  0  2  0  4  0  2  1 47]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        45\n",
      "           1       0.89      0.98      0.94        52\n",
      "           2       0.98      0.89      0.93        53\n",
      "           3       0.91      0.93      0.92        54\n",
      "           4       0.94      0.98      0.96        48\n",
      "           5       0.93      0.91      0.92        57\n",
      "           6       0.98      0.98      0.98        60\n",
      "           7       0.94      0.94      0.94        53\n",
      "           8       0.96      0.90      0.93        61\n",
      "           9       0.91      0.89      0.90        57\n",
      "\n",
      "    accuracy                           0.94       540\n",
      "   macro avg       0.94      0.94      0.94       540\n",
      "weighted avg       0.94      0.94      0.94       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9388888888888889\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  1  0  0  0  0  0  0]\n",
      " [ 1  1 47  1  0  0  0  2  1  0]\n",
      " [ 0  0  1 50  0  1  0  0  0  2]\n",
      " [ 0  0  0  0 47  0  0  1  0  0]\n",
      " [ 1  0  0  0  1 52  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  0  0  0  2  0  0 50  1  0]\n",
      " [ 0  3  0  1  0  1  0  0 55  1]\n",
      " [ 1  1  0  2  0  2  0  0  0 51]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gskim\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        45\n",
      "           1       0.96      0.96      0.96        52\n",
      "           2       0.98      0.89      0.93        53\n",
      "           3       0.98      0.94      0.96        54\n",
      "           4       0.96      0.96      0.96        48\n",
      "           5       0.96      0.96      0.96        57\n",
      "           6       1.00      0.97      0.98        60\n",
      "           7       0.96      0.94      0.95        53\n",
      "           8       0.92      0.97      0.94        61\n",
      "           9       0.85      0.93      0.89        57\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.95       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.95\n",
      "Confusion matrix:\n",
      "[[44  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  2]\n",
      " [ 2  1 47  0  0  0  0  0  2  1]\n",
      " [ 0  0  0 51  0  0  0  0  1  2]\n",
      " [ 0  0  0  0 46  0  0  2  0  0]\n",
      " [ 0  0  0  0  0 55  0  0  0  2]\n",
      " [ 0  0  1  0  0  0 58  0  1  0]\n",
      " [ 0  0  0  0  2  0  0 50  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 59  1]\n",
      " [ 1  0  0  1  0  1  0  0  1 53]]\n"
     ]
    }
   ],
   "source": [
    "# Gardient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.96      0.98      0.97        52\n",
      "           2       1.00      1.00      1.00        53\n",
      "           3       1.00      0.98      0.99        54\n",
      "           4       0.98      0.98      0.98        48\n",
      "           5       0.98      0.96      0.97        57\n",
      "           6       0.98      0.98      0.98        60\n",
      "           7       0.96      0.98      0.97        53\n",
      "           8       0.97      0.98      0.98        61\n",
      "           9       0.98      0.96      0.97        57\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9814814814814815\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 53  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 47  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 55  1  0  0  1]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 52  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 60  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "clf = GradientBoostingRegressor()\n",
    "import numpy as np\n",
    "crossvalidation = KFold(n_splits=10, shuffle=True,\n",
    "                    random_state=1)\n",
    "scores = cross_val_score(clf, X, y,\n",
    "                         scoring='neg_mean_squared_error', \n",
    "cv=crossvalidation, n_jobs=1)\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(512,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) Result of Classification : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.96      0.98      0.97        52\n",
      "           2       1.00      1.00      1.00        53\n",
      "           3       1.00      0.98      0.99        54\n",
      "           4       0.98      0.98      0.98        48\n",
      "           5       0.98      0.96      0.97        57\n",
      "           6       0.98      0.98      0.98        60\n",
      "           7       0.96      0.98      0.97        53\n",
      "           8       0.97      0.98      0.98        61\n",
      "           9       0.98      0.96      0.97        57\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "\n",
      "Accuracy:\n",
      "0.9814814814814815\n",
      "Confusion matrix:\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 53  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 47  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 55  1  0  0  1]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 52  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 60  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 55]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(512, ),\n",
    "                   activation='relu',\n",
    "                   solver='adam',\n",
    "                   shuffle=True,\n",
    "                   tol=1e-4,\n",
    "                   random_state=1)\n",
    "# Model fitness\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = clf.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(\"{} Result of Classification : \\n{}\\n\".format(clf,metrics.classification_report(y_t, y_pred)))\n",
    "print(\"Accuracy:\\n{}\".format(metrics.accuracy_score(y_t, y_pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(metrics.confusion_matrix(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.001, penalty=l1 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=0.001, penalty=l1, total=   0.0s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l2, total=   0.1s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l2, total=   0.1s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l2, total=   0.1s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l2, total=   0.1s\n",
      "[CV] C=0.001, penalty=l2 .............................................\n",
      "[CV] .............................. C=0.001, penalty=l2, total=   0.1s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.1s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.1s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.1s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.1s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.1s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.1s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.2s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.2s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.1s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.2s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.5s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.5s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.4s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.2s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.7s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.7s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.5s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   1.1s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.8s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.3s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.3s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.3s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.4s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.3s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l1, total=   0.6s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l1, total=   0.7s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=1000, penalty=l1, total=   0.5s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l1, total=   1.1s\n",
      "[CV] C=1000, penalty=l1 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l1, total=   0.7s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l2, total=   0.3s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l2, total=   0.4s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l2, total=   0.3s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l2, total=   0.6s\n",
      "[CV] C=1000, penalty=l2 ..............................................\n",
      "[CV] ............................... C=1000, penalty=l2, total=   0.3s\n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
      "                                          fit_intercept=True,\n",
      "                                          intercept_scaling=1, l1_ratio=None,\n",
      "                                          max_iter=100, multi_class='auto',\n",
      "                                          n_jobs=None, penalty='l2',\n",
      "                                          random_state=None, solver='liblinear',\n",
      "                                          tol=0.0001, verbose=0,\n",
      "                                          warm_start=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 1, 100, 1000],\n",
      "                          'penalty': ['l1', 'l2']}],\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "             scoring='accuracy', verbose=2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.92      0.92      0.92        52\n",
      "           2       0.98      1.00      0.99        53\n",
      "           3       1.00      0.94      0.97        54\n",
      "           4       0.96      0.98      0.97        48\n",
      "           5       0.95      0.95      0.95        57\n",
      "           6       0.95      0.98      0.97        60\n",
      "           7       0.98      0.96      0.97        53\n",
      "           8       0.92      0.90      0.91        61\n",
      "           9       0.93      0.95      0.94        57\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.96      0.96      0.96       540\n",
      "\n",
      "accuracy is 0.9574074074074074\n",
      "[[45  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 48  0  0  0  0  2  0  2  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 51  0  0  0  0  2  1]\n",
      " [ 0  0  0  0 47  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 54  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 59  0  0  0]\n",
      " [ 0  0  0  0  2  0  0 51  0  0]\n",
      " [ 0  3  1  0  0  1  0  0 55  1]\n",
      " [ 0  0  0  0  0  2  0  0  1 54]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   20.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Grid SearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid =[\n",
    "    {'penalty':['l1','l2'], 'C':[0.001, 0.01, 0.1, 1,1,100,1000]},\n",
    "  ]\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, \n",
    "                           scoring='accuracy', verbose=2, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_tr, y_tr)\n",
    "\n",
    "# Forecasting depend on model\n",
    "y_pred = grid_search.predict(X_t)\n",
    "\n",
    "# Model Identification \n",
    "print(grid_search)\n",
    "print(metrics.classification_report(y_t, y_pred))\n",
    "print('accuracy is',metrics.accuracy_score(y_pred, y_t))\n",
    "print(metrics.confusion_matrix(y_t, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 64 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "plt.bar(range(len(feature_importances)), feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
